{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Este notebook utiliza uma dense neoron network to classify books \n",
    "\n",
    "\n",
    "Este notebook utiliza o data set produzido no notebook \"Phrase2VecPortuguese\" para classificar livros a partir de seus dados bibliogŕaficos. O dataset foi gerado a partir da coleta de dados de diverssas bibliotecas e contém como label o número CDD e a descrição biblografica previamente vetorizada. \n",
    "\n",
    "Utilizando tensorflow para cria um rede neural densa o modelo criado tem como objetivo a partir dos dados bibligraficos calcular o primeiro nível do CDD 000 - 90.  A pesar do método de regreção ninear talves não seja  o método pois o CDD não se trata de uma escala numérica (ver descrição abixo), sua utlização pode trazer bons resultados. \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Classificação CDD \n",
    "\n",
    "A Classificação Decimal de Dewey (em inglês: Dewey Decimal Classification; DDC ou CDD) é um sistema de classificação documentária desenvolvido pelo bibliotecário americano Melvil Dewey (1851–1931).\n",
    "a Classificação CDD é amplamente utilizada em bibliotecas e seu proposito é reunir e organizar para para o docuemnto ser \"achavel\". \n",
    "https://pt.wikipedia.org/wiki/Classifica%C3%A7%C3%A3o_decimal_de_Dewey\n",
    "\n",
    "A CDD trabalha em de forma hierarquica, onde se pode aprofudar a classificação seguinto temas e sub temas, sendo o primeito nível apresenftado seguir: \n",
    "000 Generalidades\n",
    "100 Filosofia\n",
    "200 Religião\n",
    "300 Ciências sociais\n",
    "400 Línguas\n",
    "500 Ciências puras\n",
    "600 Ciências aplicadas\n",
    "700 Artes\n",
    "800 Literatura\n",
    "900 História e geografia\n",
    "\n",
    "Para realizar um software capaz de prever a CDD de um livro com base no titulo, autor e assunto. Por meio de Spiders nos juntamso em um dataset contendo a descrição dos livros e sua respectiva classificação nas base da dados da rede de bibliotecca de sâo paulo : http://bibliotecacircula.prefeitura.sp.gov.br/pesquisa/ ' na bibloteca Nacional   http://acervo.bn.br/sophia_web/index.html. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Primeiro passo - Carregar o dataset contendo cdd, descrição bibliografica veorizada\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Size X vector size  45962 x  10000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "pathclas = '/home/desenvolvimento/python/dataset/producao/classificacaioVector_v.csv'\n",
    "dataclas = pd.read_csv( pathclas);\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def getArrayFrom( strteste, fixedsize ):\n",
    "    original = np.fromstring(strteste, dtype=float, sep=' ')\n",
    "    size = len(original)\n",
    "    if size < fixedsize:\n",
    "        zeros= np.zeros(fixedsize- size) \n",
    "        original = np.concatenate((original, zeros), axis=0)\n",
    "        \n",
    "    elif size > fixedsize:\n",
    "        original = original[0:fixedsize]\n",
    "        \n",
    "        \n",
    "    return original    \n",
    "dataclas.shape  # DataFrame (45962, 2) | numpy.int64 str  \n",
    "matrixSize = 200 * 50 # 220 words with 50 dimentions  \n",
    "sizedataset= len(dataclas)\n",
    "\n",
    "print('Dataset Size X vector size ' , sizedataset, 'x ',  matrixSize)\n",
    "\n",
    "labels = np.zeros(sizedataset)\n",
    "wordvects = np.zeros((sizedataset, matrixSize), dtype=float) \n",
    "\n",
    "\n",
    "#for i in range(sizedataset):\n",
    "for i in range(sizedataset):    \n",
    "    label =dataclas.iloc[i][0]\n",
    "    wordvec =dataclas.iloc[i][1]\n",
    "    if label < 1000:\n",
    "        labels[i] =label /100\n",
    "        vecttemp =  getArrayFrom(wordvec, matrixSize )\n",
    "        wordvects[i]= vecttemp\n",
    "        \n",
    "        \n",
    "def getbachTrain(size):\n",
    "    index = np.random.choice(sizedataset, size)\n",
    "    xbach = wordvec[index]\n",
    "    ybach = labels[index]\n",
    "    return xbach, ybach \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 10000)\n",
      "(5,)\n",
      "[9.37 2.7  0.01 3.41 5.35]\n"
     ]
    }
   ],
   "source": [
    "sizedataset = len(labels)  \n",
    "\n",
    "def getbachTrain(size):\n",
    "    index = np.random.choice(sizedataset, size)\n",
    "    xbach = wordvects[index]\n",
    "    ybach = labels[index]\n",
    "    return xbach, ybach \n",
    "\n",
    "xbach, ybach  = getbachTrain(5)\n",
    "print (xbach.shape)\n",
    "print (ybach.shape)\n",
    "print (ybach)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45962\n",
      "Distribuição das classificações do nosso dataset\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# filtra as classificacoes erradas \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(sizedataset)\n",
    "\n",
    "print('Distribuição das classificações do nosso dataset' )\n",
    "\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.hist(labels)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Arquiterura da solução  \n",
    "    1. Input\n",
    "    2. Hiden layer com duas camadas (w1 e w2)\n",
    "    3. Camada fincal WF\n",
    "    4. Função custo distância vetorial  \n",
    "    \n",
    "\n",
    "\n",
    "<img src=\"https://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1547672259/3_qwv5gr.png\">\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45962\n"
     ]
    }
   ],
   "source": [
    "# meta parametros para nossa rede neural \n",
    "\n",
    "\n",
    "optimizerrate = 0.01\n",
    "\n",
    "\n",
    "# Network Parameters\n",
    "num_input = 10000 # MNIST data input (img shape: 28*28)\n",
    "matrixSize = 10000\n",
    "n_hidden_1 = 2000 # 2000 1st layer number of neurons\n",
    "n_hidden_2 = 200 # 100  layer number of neurons\n",
    "num_classes = 1 # regreção lineas \n",
    "print(sizedataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'w2_1:0' shape=(200, 2000) dtype=float32_ref>\n",
      "<tf.Variable 'b2_1:0' shape=(200, 1) dtype=float32_ref>\n",
      "Tensor(\"y2_1:0\", shape=(200, ?), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "# num_input 10000\n",
    "X = tf.placeholder(tf.dtypes.float32, [None, num_input])\n",
    "Y = tf.placeholder(tf.dtypes.float32, [None])\n",
    "\n",
    "\n",
    "# layer 1 (.. X,  2000) \n",
    "\n",
    "w1 = tf.Variable(tf.random_normal([n_hidden_1 , num_input], stddev=0.35,\n",
    "                                  dtype=tf.dtypes.float32 ),\n",
    "                        name=\"w1\" , dtype=tf.dtypes.float32 )\n",
    "\n",
    "b1 = tf.Variable(tf.zeros([n_hidden_1, 1]), name='b1', dtype=tf.dtypes.float32)\n",
    "\n",
    "y1 = tf.nn.relu(tf.add(tf.matmul(w1, tf.transpose(X)), b1), name='y1')\n",
    "\n",
    "# layer 2 (.. X,  100) \n",
    "\n",
    "w2 = tf.Variable(tf.random_normal([n_hidden_2 , n_hidden_1], stddev=0.35),\n",
    "                        name=\"w2\" , dtype=tf.dtypes.float32 )\n",
    "\n",
    "b2 = tf.Variable(tf.zeros([n_hidden_2, 1]), name='b2', dtype=tf.dtypes.float32)\n",
    "\n",
    "y2 = tf.nn.relu(tf.add(tf.matmul(w2, y1), b2), name='y2')\n",
    "\n",
    "\n",
    "\n",
    "# last lawer (.. X, 1) \n",
    "\n",
    "wf = tf.Variable(tf.random_normal([num_classes , n_hidden_2], stddev=0.35),\n",
    "                        name=\"wf\" , dtype=tf.dtypes.float32 )\n",
    "\n",
    "bf = tf.Variable(tf.zeros([num_classes, 1]), name='bf', dtype=tf.dtypes.float32)\n",
    "\n",
    "y_f  = tf.add(tf.matmul(wf, y2), bf, name=\"y_f\")\n",
    "\n",
    "\n",
    "\n",
    "#y1 = tf.matmul(w1, tf.transpose(X))\n",
    "\n",
    "print(w2)\n",
    "print(b2)\n",
    "print(y2)\n",
    "\n",
    "#Returns (x - y)(x - y) element-wise.\n",
    "loss = tf.reduce_mean(tf.squared_difference(y_f, Y))\n",
    "\n",
    "#optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.0001).minimize(loss)\n",
    " \n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=optimizerrate).minimize(loss)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000 X 200 0.01 300 1600 =\n",
      "Optimization Iteration:  0  erro  médio:  6934.969069866137\n",
      "Optimization Iteration:  100  erro  médio:  5.9641699669589725\n",
      "Optimization Iteration:  200  erro  médio:  4.885870721968807\n",
      "Optimization Iteration:  300  erro  médio:  4.22581286313628\n",
      "Optimization Iteration:  400  erro  médio:  3.4610442754321222\n",
      "Optimization Iteration:  500  erro  médio:  3.1654620807445077\n",
      "Optimization Iteration:  600  erro  médio:  2.728566742010664\n",
      "Optimization Iteration:  700  erro  médio:  2.6711253402818995\n",
      "Optimization Iteration:  800  erro  médio:  2.3005912974365037\n",
      "Optimization Iteration:  900  erro  médio:  2.21005047908802\n",
      "Optimization Iteration:  1000  erro  médio:  2.084035055872435\n",
      "Optimization Iteration:  1100  erro  médio:  1.9492844320174307\n",
      "Optimization Iteration:  1200  erro  médio:  1.8104077463694812\n",
      "Optimization Iteration:  1300  erro  médio:  1.7423880423176683\n",
      "Optimization Iteration:  1400  erro  médio:  1.8041799913344543\n",
      "Optimization Iteration:  1500  erro  médio:  1.7004395057037411\n",
      "f 11.565978\n"
     ]
    }
   ],
   "source": [
    "session = tf.Session()\n",
    "session.run(tf.global_variables_initializer())\n",
    "\n",
    "#2.2534682e+19\n",
    "#45962\n",
    "bachsize = 300\n",
    "ntraining = 1600\n",
    "print( n_hidden_1 ,'X', n_hidden_2, optimizerrate ,  bachsize , ntraining,  '=' ) \n",
    "\n",
    "for i in range(ntraining):\n",
    "\n",
    "    xbach, ybach  = getbachTrain(bachsize)\n",
    "    feed_dict_train = {X: xbach,   Y: ybach}\n",
    "    result = session.run(optimizer, feed_dict=feed_dict_train)\n",
    "    if i % 100  == 0:\n",
    "        resultloss = session.run(loss, feed_dict=feed_dict_train)\n",
    "        print('Optimization Iteration: ', i,  ' erro  médio: ', ((resultloss ** (1/2)))  )\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "print('f', resultloss)\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    " A Regreção obteve algum exito chegando ao um erro médio de 1.7 numa escala de 0-10. \n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
